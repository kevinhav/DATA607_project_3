---
title: "The most important skill to a data scientist is email"
author: "Havis, Koon, Tillmawitz"
format: html
---

```{r}
library(tidyverse)
library(knitr)
library(kableExtra)
library(zoo)
library(scales)
```


## Introduction

## ONET

The O*NET database includes information on skills, abilities, knowledge, work activities, and interests associated with occupations. This information can be used to facilitate career exploration, vocational counseling, and a variety of human resources functions, such as developing job orders and position descriptions and aligning training with current workplace needs.

For our analysis we have isolated Data Scientists and Statisticians as the primary occupations of interest. Note that Data Scientist is considered a "parent" occupation, and includes the sub-occupations of Business Intelligence Analyst and Clinical Data Managers. O\*NET groups occupations according to how similar it finds their "work activities" to be. We will collectively refer to these occupations as "data scientists" going forward.

```{r}
# Load all ONET data
source('../data/raw/load_onet_historical_data.R')
```


### skills

The analysts behind O\*NET data measure skills relevancy to an occupation in two ways; *Level* and *Importance.*

*Level* refers to the degree of expertise the job requires. For example, surgery might be a relevant skill for both a nurse and a surgeon, however the surgeon would require a much higher level in the skill.

*Importance* refers to how many work activities require the use of such a skill. Using another example, Service Orientation would have a very high level of importance to a waiter in a restaurant, but perhaps a low level required (depending on the restaurant).

Both of these dimensions are rated on a scale of 1 - 5, with one being the lowest and five being the highest.

```{r}
skills <- onet_24$skills

kable(head(skills))
```



```{r, fig.width= 6, fig.height = 6}
top_skills <- skills |> 
  group_by(element_name) |> 
  summarize(max_value = max(data_value), .groups = "drop") |> 
  arrange(desc(max_value)) |> 
  slice_head(n=15) |> 
  pull(element_name)

skills |> 
  filter(element_name %in% top_skills) |> 
  arrange(desc(data_value), element_name, scale_id) |> 

ggplot(aes(x = fct_reorder(element_name, data_value, .fun = max, .desc = FALSE), y = data_value, fill = scale_id)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.8) +
  coord_flip() +
  labs(
    title = "Top Skills for Data Scientists",
    x = "Skill",
    y = "Rating",
    fill = c("Level", "Importance"),
    caption = "Based on 2024 O*NET Data"
  ) +
  theme_minimal() +
  theme(plot.caption = element_text(hjust = 0, face = "italic"),
        plot.title.position = "plot",
        plot.caption.position = "plot") +
  scale_fill_manual(
    name = "Rating Type",
    labels = c("LV" = "Level", "IM" = "Importance"),
    values = c("LV" = "#203D46", "IM" = "#B83F21")
  ) +
  scale_y_continuous(breaks = c(1, 2, 3, 4, 5))
```

As we can see, the top five skills by both importance and level are Mathematics, Reading Comprehension, Critical Thinking, and Writing. None of these are particularly surprising on their own, but other skills commonly associated with data science are ranked much lower, such as Technology Design, Programming, and Systems Evaluation.

In general, we can see that the "soft skills" that are more focused on human interaction are generally more frequently applied and important in data science, including Speaking, Active Listening, and Judgement & Decision Making.

### Abilities

Abilities differ from skills in that they refer more to an individual's enduring attributes, and are less likely to be actively developed. You could think of abilities in this context as a person's natural proclivities.

similar to skills, abilities are rated again by Level and Importance.

```{r}
abilities <- onet_24$abilities

kable(head(abilities))
```

```{r, echo = FALSE, fig.width= 6, fig.height = 6}
# Create vector of top abilities
top_abilities <- abilities |> 
  group_by(element_name) |> 
  summarize(max_value = max(data_value), .groups = "drop") |> 
  arrange(desc(max_value)) |> 
  slice_head(n=15) |> 
  pull(element_name)

# Filter dataframe for top abilities
abilities |> 
  filter(element_name %in% top_abilities) |> 
  arrange(desc(data_value), element_name, scale_id) |> 
# Visualize
ggplot(aes(x = fct_reorder(element_name, data_value, .fun = max, .desc = FALSE), y = data_value, fill = scale_id)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.8) +
  coord_flip() +
  labs(
    title = "Top Abilities for Data Scientists",
    x = "Ability",
    y = "Rating",
    fill = c("Level", "Importance"),
    caption = "Based on 2024 O*NET Data"
  ) +
  theme_minimal() +
  theme(plot.caption = element_text(hjust = 0, face = "italic"),
        plot.title.position = "plot",
        plot.caption.position = "plot") +
  scale_fill_manual(
    name = "Rating Type",
    labels = c("LV" = "Level", "IM" = "Importance"),
    values = c("LV" = "#203D46", "IM" = "#B83F21")
  ) +
  scale_y_continuous(breaks = c(1, 2, 3, 4, 5))
```

Following closely the trend we observed in the Skills data, we can see that handiness with numbers, as well as strong capacity to communicate with others, are both important and require a high degree of expertise for an aspiring data scientist.

Despite these similarities, we liked the abilities view as it more finely demonstrated the importance of "soft skills", primarily those that focused on communication. We continue to see reinforcement for data scientists to invest in their writing and presentation skills!

### Technology skills

Technology skills are associated with a given occupation based on requirements seen in relevant job postings. 

"Hot Technology" indicates that this particular skill is popular across occupations, while "in demand" indicates requirements frequently included in job postings for the particular occupation of data scientist.

```{r}
tech_skills <- onet_24$tech

kable(head(tech_skills))
```

When looking at In Demand skills for data scientist, we can see those that are unique to the profession when Hot Technology is "N". This indicates that experience in this type of software is not commonly required in today's job market, however is highly sought after for data scientists specifically.

```{r}
tech_skills |>  
  filter(in_demand == "Y", soc_name == "data_scientist") |> 
  select(commodity_title, example, hot_technology, in_demand) |> 
  arrange(commodity_title) |> 
  rename("Category" = commodity_title, "Software" = example, "Hot Technology" = hot_technology, "In Demand" = in_demand) |> 
  kable() |> 
  kable_styling(bootstrap_options = "hover") |> 
  row_spec(c(8, 9, 10, 13, 15), background = "#B83F21")
```

Some notable examples include popular Python libraries such as Numpy, Pandas, PyTorch, and Scikit-Learn. 

The usual suspects, which are more universally sought across occupations, include SQL, AWS, and Git.

We will see more of how technology skills relate to a given occupation, especially quantitatively, in the following section.


### Additional Information

O\*NET contains a vast store of interesting data related to many other occupations, and we strongly encourage others to explore if for nothing else than to satisfy your curiosity.

[About O\*NET](https://www.onetcenter.org/overview.html) - Read more on how O*NET Data is captured and analyzed
[O\*NET Resource Center](https://www.onetcenter.org/) - Additional data, taxonomies, and methodologies
[O\*NET Interest Profiler](https://www.onetcenter.org/IP.html#web-based) - Survey tool to profile your interests and align to different occupations

## What skills are most valuable?

Nailing down the value of a skill can be difficult, as value can be defined any number of ways. Additionally, soft skills are simply hard to measure. When has one attained mastery of written expression or speaking? The thresholds and measures of such skills are subjective and therefore difficult to track. Technical skills, however, are a bit easier to measure. While defining mastery of a technical skill is still nebulous, a common practice across the tech industry is to conduct a technical interview which evaluates a candidate's skills with the technologies the role requires. We can therefore conclude that if an individual uses a technology in their role they have a baseline competency that meets the standards of the industry. Having set a threshold for skill competency, we still need to determine how to value the skill. The O\*NET data has given us the relative value of these skills, but we can attach a more absolute value to a skill by tracking the average salary of individuals with said skill.

### The Stack Overflow Developer Survey

Every year Stack Overflow conducts a voluntary survey of its users. While not strictly a representative sample of the industry it is the closest thing to one that is publicly available due to the reliance of tech workers on the Stack Overflow forums. The survey is considered one of the best resources for tracking tech trends and conveniently also tracks the role and salary of respondents as well as numerous other indicators. For our purposes we will be looking at the skills and tools used by data scientists in their current role.

### Tidying the Data

The survey covers all kinds of developers, of which data scientists make a relatively small proportion of the sample. While there is a "Data scientist or machine learning specialist" category, we are expanding our sample to include roles that have significant overlap in skills and duties which can be filled by individuals who may otherwise be considered data scientists. The developer types we will look at are "Data engineer", "Data scientist or machine learning specialist", "Data or business analyst", and "Developer, AI". Normally we would want to address missing values for skills, but in this case the value of a skill is defined as much by who has it as who does not as those with specialized knowledge can demand a higher salary. For our purposes we will consider any skill that fewer than 10% of our sample population have as too niche to be considered.

```{r transform the data into format for analysis, results = FALSE, message=FALSE}
#| code-fold: true
# Change this as needed, absolute path works better than relative for me
file_path <- "/Users/matttillman/School/DATA607_project_3/data/processed/stack_overflow_jobs.csv"
so_data <- read_csv(file_path) |>
  select(!c("OfficeStackSyncHaveWorkedWith", "OfficeStackAsyncHaveWorkedWith"))
total_devs <- nrow(so_data)

# Need to hide this
cutoff <- 0.1 * total_devs

grouped_skills <- so_data |>
  rowid_to_column("id") |>
  mutate(across(!c(id, DevType, ConvertedCompYearly), ~ gsub(';', paste0("_", cur_column(), ";"), .))) |>
  mutate(across(!c(id, DevType, ConvertedCompYearly), ~ if_else(!is.na(.), paste0(., "_", cur_column()), .)))

skills_chart <- grouped_skills |>
  unite("skills", LanguageHaveWorkedWith:AISearchDevHaveWorkedWith, sep = ";", na.rm = TRUE) |>
  separate_longer_delim(skills, delim = ";") |>
  mutate(present = 1) |>
  filter(skills != "") |>
  distinct() |> 
  pivot_wider(id_cols = c(id, DevType, ConvertedCompYearly), names_from = skills, values_from = present, values_fill = 0) 

skill_population <- skills_chart |>
  summarise(across(!c(id, DevType, ConvertedCompYearly), ~ sum(.))) |>
  pivot_longer(everything(), names_to = "skill", values_to = "count") |>
  separate_wider_delim(skill, delim = "_", names = c("skill", "skill_group"))

skills_above_cutoff <- skill_population |>
  filter(count > cutoff)

smash_skills <- skills_above_cutoff |>
  unite("skill", c(skill,skill_group), sep = "_")

relevant_skills_chart <- skills_chart |>
  select(c(id, DevType, ConvertedCompYearly) | smash_skills$skill)

all_relevant_skills_rank <- relevant_skills_chart |>
  pivot_longer(!c("id", "DevType", "ConvertedCompYearly"), names_to = "skill", values_to = "has_skill") |>
  filter(has_skill > 0) |>
  group_by(skill) |>
  summarise(avg_comp = mean(ConvertedCompYearly)) |>
  separate_wider_delim(skill, delim = "_", names = c("skill", "skill_group")) |>
  arrange(desc(avg_comp)) |>
  filter(skill_group != "NEWCollabToolsHaveWorkedWith") |>
  mutate(skill_group = str_replace(skill_group, "HaveWorkedWith", ""))
```

When we look at the top skills by average salary we can see some interesting patterns. In terms of "skill groups" there does not appear to be a single kind of skill that is more valuable than others. Having a diverse scope of knowledge across the surveyed technology types appears to lead to higher salaries, as every skill group has at least one technology in the top third of average salaries. In the bottom third of the plot we can find technologies like MongoDB or MySQL which have largely been supplanted by newer or more performant technologies. The middle third of the chart is populated by what we can consider to be the expected standard skills, technologies which do not differentiate a candidate but are also not correlated with lower paying jobs. Technologies like R, Pandas, Python, Docker, and PostgreSQL fall into this category. There is a clear jump in the value of skills with an average salary over $100,000 indicating these skills are differentiators in the industry. Familiarity with tools such as Kafka, Spark, Databricks, Terraform, AWS, and Snowflake as well as the associated skills of interpreting and manipulating data in real time at scale are clearly a big selling point for employers. Interestingly we see an AI tool topping the list in Claude, and another in Github Copilot near the top. This seems to indicate that familiarity with AI tools can be a differentiator, although the lack of other AI tools making the cutoff for relevant skills means the specific tool matters. It will be interesting to see whether the AI tools remain relevant or if they get supplanted in time.

```{r plotting skills, fig.height=10, fig.width=10}
#| code-fold: true
all_relevant_skills_rank |>
  arrange(desc(avg_comp)) |>
  ggplot(aes(x = avg_comp, y = fct_reorder(skill, avg_comp), fill = skill_group)) +
  geom_col() +
  theme(legend.position = "bottom",
        axis.title = element_text(size = 15),
        legend.title = element_text(size = 15),
        title = element_text(size = 20)) +
  scale_x_continuous(labels = label_comma()) +
  labs(title = "Technical Skills by Value", x = "Average Salary (USD)", y = "Technology Used", fill = "Skill Group")
```

Tieing our analysis back into the O\*NET data we can use the tech skills explicitly identified as reference points to expand our understanding of the relative value of skills not included in the O\*NET data. It should be noted that GIT, SAS, Hadoop, and Excel do not appear in the data we pulled from the Stack Overflow Survey. Hadoop is an outdated technology that has been supplanted by Spark, so we can safely disregard it. GIT is a surprising omission from this dataset and given its prevalence as a development tool it likely appears in one of the categories that was not pulled. The same can be said of SAS and Excel, which are the only remaining omissions. Several of the technologies listed in the O\*NET technical skills are families of technologies, most notably SQL and NoSQL so in those cases technologies which are part of those families are colored the same.

```{r plotting skills highlighted, fig.height=10, fig.width=10}
#| code-fold: true
tech_colors <- c(
  "R" = "#8AB17D", 
  "Python" = "#4A7A8C", 
  "Git" = "#E7B16C", 
  "Amazon Web Services (AWS)" = "#D9421C", 
  "Redis" = "#E9C46A", 
  "Elasticsearch" = "#E9C46A", 
  "MongoDB" = "#E9C46A",
  "SAS" = "#BABB74", 
  "Apache Spark" = "#F4A261", 
  "Hadoop" = "#E76F51", 
  "Excel" = "#264653", 
  "Databricks SQL" = "#2A9D8F", 
  "PostgreSQL" = "#2A9D8F", 
  "SQL" = "#2A9D8F", 
  "Microsoft SQL Server" = "#2A9D8F", 
  "SQLite" = "#2A9D8F", 
  "MySQL" = "#2A9D8F",
  "Pandas" = "#47856A", 
  "Scikit-Learn" = "#864653", 
  "TensorFlow" = "#99756F"
) 

all_relevant_skills_rank |>
  arrange(desc(avg_comp)) |>
  ggplot(aes(x = avg_comp, y = fct_reorder(skill, avg_comp), fill = skill)) +
  geom_col() +
  theme(legend.position = "bottom",
        axis.title = element_text(size = 15),
        legend.title = element_text(size = 15),
        title = element_text(size = 20)) +
  scale_x_continuous(labels = label_comma()) +
  labs(title = "Technical Skills by Value", x = "Average Salary (USD)", y = "Technology Used", fill = "Skill Group") +
  scale_fill_manual(values = tech_colors)
```


## What skills are people training in?

Linkedin Learning is a skill development platform launched in 2016.  It provides eLearning resources that focus on four main categories, Business, Technology, Creative, and Certifications.  For this analysis, data was pulled from the Data Science and Artificial Intelligence topics in the Technology category.  

# Data Acquisition

To obtain this data, we used Python, Beautiful Soup, and Selenium to scrape the LinkedInLearning catalog for links to the main course pages.  With the list of links, we then automated navigation to each main course page and scraped the overarching course topic, course title, description, published date, to-date enrollment, and skill tags.  

```{r}
# Load all LinkedInLearning Data
LL_Data_Science <- read.csv("../data/raw/Data-Science_Data.csv", header = TRUE, sep = ";")
LL_Artificial_Intelligence <- read.csv("../data/raw/Artificial-Intelligence_Data.csv", header = TRUE, sep = ";")
full_LL_dataset <- rbind(LL_Data_Science,LL_Artificial_Intelligence) 
```

# Data Cleaning

The raw dataset contained skill tags as a list in the last column.  These skills were separated and converted to their own individual record.  Since Viewership is dependent on Published Date, the data was standardized by including the column Active Days which denote how many days the course has been active, based on the date of data acquisition and the date of course publication.  YearMonth, which takes the year and month of course publication, was also included into the full dataset in the data cleaning process. 

```{r}
full_LL_dataset <- full_LL_dataset %>% rename(Topic = X0, Title = X1, Published = X2, Enrollment = X3, Description = X4, Skills = X5)
full_LL_dataset$Skills <- substr(full_LL_dataset$Skills, 2, nchar(full_LL_dataset$Skills) - 1)
full_LL_dataset <- separate_rows(full_LL_dataset, Skills, sep = ",")
full_LL_dataset$Skills <- gsub("^'|'$", "", trimws(full_LL_dataset$Skills))

full_LL_dataset <- full_LL_dataset %>% 
  mutate(Published = as.Date(Published)) %>% 
  mutate(active_days = as.numeric(as.Date("2024-10-16")-Published)) %>% 
  mutate(YearMonth = as.yearmon(Published))

```
# Technology Skills

For consistency, the skills centered in this analysis follow the shortlist from the previous sections.  

```{r}
full_LL_dataset_onet_mapped <- full_LL_dataset %>% distinct(Title, Published, Skills, .keep_all = TRUE) %>%   
  mutate(skills_onet = case_when( # rename the skills as named in LinkedInLearning to match onet data
    Skills == "R (Programming Language)"      ~ "R",
    Skills == "Python (Programming Language)" ~ "Python",
    Skills == "GitHub"   ~ "Git",
    Skills == "Amazon Web Services (AWS)"    ~ "AWS",
    Skills == "Apache Spark"    ~ "Spark",
    Skills == "Excel Dashboards"      ~ "Excel",
    Skills == "Excel Modeling"      ~ "Excel",
    Skills == "Microsoft Excel"      ~ "Excel",
    Skills == "Pandas (Software)" ~ "Pandas",
    Skills == "Scikit-Learn"   ~ "Scikit-learn",
    Skills == "SAS (Programming Language)"   ~ "SAS",
    Skills == "SQL"    ~ "SQL",
    Skills == "Hadoop"    ~ "Hadoop",
    Skills == "NoSQL"    ~ "NoSQL",
    Skills == "TensorFlow"    ~ "TensorFlow"
  )) %>% na.omit() # remove all data that does not fall within these categories


tech_colors <- c(
  "R" = "#8AB17D", 
  "Python" = "#4A7A8C", 
  "Git" = "#E7B16C", 
  "AWS" = "#D9421C", 
  "NoSQL" = "#E9C46A", 
  "SAS" = "#BABB74", 
  "Spark" = "#F4A261", 
  "Hadoop" = "#E76F51", 
  "Excel" = "#264653", 
  "SQL" = "#2A9D8F", 
  "pandas" = "#47856A", 
  "Scikit-learn" = "#864653", 
  "TensorFlow" = "#99756F"
) 

```

For the base analysis, we can look at total viewership by Technology Skill.  We can see the top four skills are Excel, SQL, Python, and R, with Excel leading by a significant margin.  The top four skills appear to have significantly higher enrollment than the other top skills identified by the O*NET data.    

```{r}
Skill_Enrollment_onet_mapped <- full_LL_dataset_onet_mapped %>% group_by(skills_onet) %>% summarize(avg_total_daily_enrollment = sum(Enrollment)/sum(active_days), total_enrollment = sum(Enrollment)) 

Skill_Enrollment_onet_mapped %>% 
  ggplot(aes(x = total_enrollment, y = reorder(skills_onet,total_enrollment), fill = skills_onet)) + geom_bar(stat= "identity") +
    scale_fill_manual(
    values = tech_colors
  ) +
  guides(fill = "none") + 
  theme_minimal() + 
  scale_x_continuous(labels = function(total_enrollment) format(total_enrollment, scientific = FALSE)) + 
  labs(title = "Total Enrollment by Technology Skill", y = "Technology Skill", x = "Enrollment")
```
Using the number of active days per course, we can standardized the data by taking total enrollment per course and divide by total active days.  This accounts for newer courses that may have lower total viewership but high daily enrollment with respect to when the course was published. When looking at average daily enrollment, we can see that Excel again far surpasses the other technology skills.  However, the gap between all other technology skills is closed significantly.  Using this method, we can see that the top five technology skills are Excel, SQL, Python, SAS, and R.  

```{r}
Skill_Enrollment_onet_mapped %>% 
  ggplot(aes(x = avg_total_daily_enrollment, y = reorder(skills_onet,avg_total_daily_enrollment), fill = skills_onet)) + geom_bar(stat= "identity") +
    scale_fill_manual(
    values = tech_colors
  ) +
  guides(fill = "none") + 
  theme_minimal() + 
  labs(title = "Average Daily Enrollment by Technology Skill", y = "Technology Skill", x = "Average Daily Enrollment")
```
These results, specifically the lessened gap between each skill, can be explained by the fewer number of available courses or more recent publication dates.  Both of these variables will affect the number of Active Days, which was used in the standardization of data.  Taking a look at number of courses per technology skill, we can see that this is true for skills like SAS and Scikit-learn, which only had one course each resulting in a high average daily enrollment.

```{r}
Skill_Count_onet_mapped <- full_LL_dataset_onet_mapped %>% group_by(skills_onet) %>% summarize(count = n())

Skill_Count_onet_mapped %>% 
  ggplot(aes(x = count, y = reorder(skills_onet,count), fill = skills_onet)) + geom_bar(stat= "identity") +
  scale_fill_manual(
    values = tech_colors
  ) +
    guides(fill = "none") + 
  theme_minimal() +
  labs(title = "Number of Courses by Technology Skill", y = "Technology Skill", x = "Courses")
```

We can also look at the count of courses graphed against the total enrollment, where we would expect total enrollment to increase as course quantity increases.  If each technology were equally in demand for Linkedin Learners, we would expect the data to exhibit a linear trend.  We can see a clear outlier with Excel, having a high count but a much higher total enrollment that does not appear to follow the pattern of the data.  SQL also appears to be a potential outlier, though not as pronounced.  

```{r}
Skill_joined_count_avg_enroll <- inner_join(Skill_Count_onet_mapped,Skill_Enrollment_onet_mapped, by = "skills_onet")

Skill_joined_count_avg_enroll %>% 
  ggplot(aes(x = count, y = total_enrollment, color = skills_onet)) + geom_point(size = 2) +
  scale_color_manual(
    name = "Technology",
    values = tech_colors
  ) +
  guides(fill = "none") + 
  theme_minimal() +
  scale_y_continuous(labels = function(total_enrollment) format(total_enrollment, scientific = FALSE)) +
  labs(title = "Total Course Enrollment vs Available Courses", y = "Total Enrollment", x = "Number of Courses")
```
Finally, we can look at the evolution of demand in upskilling for each technology over time by determining what technology skills eLearnings are released on the platform over time. From this data, we can see that there are four technology skills, Python, SQL, Excel, and R which appear to have a catalog that is growing at a faster rate than the other skills.  

```{r}
Skill_Binned_onet_mapped <- full_LL_dataset_onet_mapped %>% group_by(YearMonth,skills_onet) %>% summarize(count = n(), .groups = 'drop') %>% group_by(skills_onet) %>% mutate(ccount = cumsum(count)) 

Skill_Binned_onet_mapped %>% ggplot(aes(x = YearMonth, y = ccount, color = skills_onet)) + geom_point(size = 2) + geom_line() +
    scale_color_manual(
      name = "Technology",
    values = tech_colors) +  
  labs(title = "Course Addition over Time", y = "Total Number of Courses", x = "Publication Date")

```
With the above results, it is important to consider the universal use of each of these skills. While Excel is present in many of the courses cataloged for "Data Science" and "Artificial Intelligence", it is also considered a basic software skill used in many other professions.  This might cause skewed numbers in favor of higher enrollment in Excel courses.  
